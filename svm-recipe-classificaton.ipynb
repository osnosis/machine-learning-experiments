{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Can we use the ingredient and keyword list to predict the rating?<br>\n",
    "\n",
    "(For someone writing a cookbook this could be really useful information that could help them choose which recipes to include because they're more likely to be enjoyed and therefore make the book more likely to be successful.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Load data. <br>\n",
    "Preview data and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20052, 680)\n",
      "                                         title  rating  calories  protein  \\\n",
      "0              Lentil, Apple, and Turkey Wrap    2.500     426.0     30.0   \n",
      "1  Boudin Blanc Terrine with Red Onion Confit    4.375     403.0     18.0   \n",
      "2                Potato and Fennel Soup Hodge    3.750     165.0      6.0   \n",
      "3             Mahi-Mahi in Tomato Olive Sauce    5.000       NaN      NaN   \n",
      "4                    Spinach Noodle Casserole    3.125     547.0     20.0   \n",
      "\n",
      "    fat  sodium  #cakeweek  #wasteless  22-minute meals  3-ingredient recipes  \\\n",
      "0   7.0   559.0        0.0         0.0              0.0                   0.0   \n",
      "1  23.0  1439.0        0.0         0.0              0.0                   0.0   \n",
      "2   7.0   165.0        0.0         0.0              0.0                   0.0   \n",
      "3   NaN     NaN        0.0         0.0              0.0                   0.0   \n",
      "4  32.0   452.0        0.0         0.0              0.0                   0.0   \n",
      "\n",
      "    ...    yellow squash  yogurt  yonkers  yuca  zucchini  cookbooks  \\\n",
      "0   ...              0.0     0.0      0.0   0.0       0.0        0.0   \n",
      "1   ...              0.0     0.0      0.0   0.0       0.0        0.0   \n",
      "2   ...              0.0     0.0      0.0   0.0       0.0        0.0   \n",
      "3   ...              0.0     0.0      0.0   0.0       0.0        0.0   \n",
      "4   ...              0.0     0.0      0.0   0.0       0.0        0.0   \n",
      "\n",
      "   leftovers  snack  snack week  turkey  \n",
      "0        0.0    0.0         0.0     1.0  \n",
      "1        0.0    0.0         0.0     0.0  \n",
      "2        0.0    0.0         0.0     0.0  \n",
      "3        0.0    0.0         0.0     0.0  \n",
      "4        0.0    0.0         0.0     0.0  \n",
      "\n",
      "[5 rows x 680 columns]\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('epi_r.csv')\n",
    "#print(list(raw_data.columns))\n",
    "print(raw_data.shape)\n",
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have 20052 recipe entries and 680 features. Now, let's get a basic statistical and visual representation of the sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20052.000000\n",
       "mean         3.714467\n",
       "std          1.340829\n",
       "min          0.000000\n",
       "25%          3.750000\n",
       "50%          4.375000\n",
       "75%          4.375000\n",
       "max          5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEFCAYAAADt1CyEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmaJ+38baQ9bTKrh8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113e77b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data.rating.hist(bins=20)\n",
    "plt.title('Histogram of Recipe Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"There are just over 20,000 recipes with an average rating of 3.71. What is interesting is that the 25th percentile is actually above the mean. This means there is likely some kind of outlier population. This makes sense when we think about reviews. People are more likely to review recipes when they have strong feelings about them. Some bad recipes may have very few very low reviews.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we use nutritional information to help build our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories    4117\n",
       "protein     4162\n",
       "fat         4183\n",
       "sodium      4119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_count = raw_data.isnull().sum()\n",
    "null_count[null_count>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nutrition information is not available for all goods. Out of ~20000 observations, there are only about 4000 for each nutritional categories. This seriously limits the scope of our data. Drop nutritional columns, for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a Support Vector Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR()\n",
    "X = raw_data.drop(['rating', 'title', 'calories', 'protein', 'fat', 'sodium'], 1)\n",
    "Y = raw_data.rating\n",
    "svr.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what a scatter plot looks like, comparing actuals to predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10e362cf8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD3CAYAAAAALt/WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113e77e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Y, svr.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the discontinous nature of our outcome variable, there's too much data for us to really see what's going on here and we end up with nebulous spreads of predictions. The classifier does at least seem to predict the 4/5 ratings at a higher spread than the rest, which is a good sign.<br>\n",
    "\n",
    "Now let's assess the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038565706512988962"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01818511  0.026411    0.03037705  0.01957949  0.02451197]\n",
      "0.0238129242667\n"
     ]
    }
   ],
   "source": [
    "svr_cv = cross_val_score(svr, X, Y, cv=5)\n",
    "print(svr_cv)\n",
    "print(svr_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very poor accuracy, and slightly overfitting.\n",
    "\n",
    "# Challenge\n",
    "\n",
    "Transform this regression problem into a binary classifier and clean up the feature set. You can choose whether or not to include nutritional information, but try to cut your feature set down to the 30 most valuable features. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's start by converting the continuous output to binary: <br>\n",
    "Create a new column that applies a function to decide whether the rating is good or bad. This converts it from continuous to binary output.<br>\n",
    "Define good as 4 or 5. <br>\n",
    "Count how many are good/bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         title  rating  calories  protein  \\\n",
      "0              Lentil, Apple, and Turkey Wrap    2.500     426.0     30.0   \n",
      "1  Boudin Blanc Terrine with Red Onion Confit    4.375     403.0     18.0   \n",
      "2                Potato and Fennel Soup Hodge    3.750     165.0      6.0   \n",
      "3             Mahi-Mahi in Tomato Olive Sauce    5.000       NaN      NaN   \n",
      "4                    Spinach Noodle Casserole    3.125     547.0     20.0   \n",
      "\n",
      "    fat  sodium  #cakeweek  #wasteless  22-minute meals  3-ingredient recipes  \\\n",
      "0   7.0   559.0        0.0         0.0              0.0                   0.0   \n",
      "1  23.0  1439.0        0.0         0.0              0.0                   0.0   \n",
      "2   7.0   165.0        0.0         0.0              0.0                   0.0   \n",
      "3   NaN     NaN        0.0         0.0              0.0                   0.0   \n",
      "4  32.0   452.0        0.0         0.0              0.0                   0.0   \n",
      "\n",
      "     ...     yogurt  yonkers  yuca  zucchini  cookbooks  leftovers  snack  \\\n",
      "0    ...        0.0      0.0   0.0       0.0        0.0        0.0    0.0   \n",
      "1    ...        0.0      0.0   0.0       0.0        0.0        0.0    0.0   \n",
      "2    ...        0.0      0.0   0.0       0.0        0.0        0.0    0.0   \n",
      "3    ...        0.0      0.0   0.0       0.0        0.0        0.0    0.0   \n",
      "4    ...        0.0      0.0   0.0       0.0        0.0        0.0    0.0   \n",
      "\n",
      "   snack week  turkey  good/bad  \n",
      "0         0.0     1.0         0  \n",
      "1         0.0     0.0         1  \n",
      "2         0.0     0.0         0  \n",
      "3         0.0     0.0         1  \n",
      "4         0.0     0.0         0  \n",
      "\n",
      "[5 rows x 681 columns]\n",
      "1    10738\n",
      "0     9314\n",
      "Name: good/bad, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def good_bad (rating):\n",
    "    if rating >= 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "raw_data['good/bad'] = raw_data['rating'].apply(good_bad)\n",
    "\n",
    "print(raw_data.head())\n",
    "print(raw_data['good/bad'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ~10000 recipes classified as \"good\" and ~9000 recipes classified as \"bad\", we aren't dealing with significant class imbalance here. Let's try running an initial classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"svm = SVC(kernel = 'linear')\\nsvm.fit(X, Y)\\n\\nprint(svm.score(X,Y))\\nsvm_cv = cross_val_score(svm, X, Y, cv=5)\\nprint(svm_cv.mean())\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = raw_data.drop(['rating', 'title', 'calories', 'protein', 'fat', 'sodium'], 1)\n",
    "Y = raw_data['good/bad']\n",
    "\n",
    "\"\"\"svm = SVC(kernel = 'linear')\n",
    "svm.fit(X, Y)\n",
    "\n",
    "print(svm.score(X,Y))\n",
    "svm_cv = cross_val_score(svm, X, Y, cv=5)\n",
    "print(svm_cv.mean())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs extremely slow for the entire dataset, so it isn't a good idea to run it for a preliminary idea. Let's cut 681 columns down to just a few to minimize run time for abbreviated experimental processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   appetizer  apple  bacon  basil  parsnip  party  lemon  quick and healthy  \\\n",
      "0        0.0    1.0    0.0    0.0      0.0    0.0    0.0                0.0   \n",
      "1        0.0    0.0    0.0    0.0      0.0    0.0    0.0                0.0   \n",
      "2        0.0    0.0    0.0    0.0      0.0    0.0    0.0                0.0   \n",
      "3        0.0    0.0    0.0    0.0      0.0    0.0    0.0                0.0   \n",
      "4        0.0    0.0    0.0    0.0      0.0    0.0    0.0                0.0   \n",
      "\n",
      "   simmer  thanksgiving  wine  leftovers  turkey  winter  pineapple  oyster  \\\n",
      "0     0.0           0.0   0.0        0.0     1.0     0.0        0.0     0.0   \n",
      "1     0.0           0.0   0.0        0.0     0.0     1.0        0.0     0.0   \n",
      "2     0.0           0.0   0.0        0.0     0.0     0.0        0.0     0.0   \n",
      "3     1.0           0.0   0.0        0.0     0.0     0.0        0.0     0.0   \n",
      "4     0.0           0.0   0.0        0.0     0.0     0.0        0.0     0.0   \n",
      "\n",
      "   paleo  vegetarian  vegan  good/bad  \n",
      "0    0.0         0.0    0.0         0  \n",
      "1    0.0         0.0    0.0         1  \n",
      "2    0.0         0.0    0.0         0  \n",
      "3    0.0         0.0    0.0         1  \n",
      "4    0.0         1.0    0.0         0  \n"
     ]
    }
   ],
   "source": [
    "new_columns = ['appetizer', 'apple', 'bacon', 'basil', 'parsnip', 'party', 'lemon', 'quick and healthy', 'simmer', \n",
    "    'thanksgiving', 'wine', 'leftovers', 'turkey', 'winter', 'pineapple', 'oyster', 'paleo', 'vegetarian', 'vegan',\n",
    "    'good/bad']\n",
    "new_data = raw_data[new_columns]\n",
    "print(new_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try and clean up the features: <br>\n",
    "- Make a correlation matrix and cut out features based on how strongly they are correlated to other features. <br>\n",
    "- Sort the features by how many other features they correlate strongly to. <br>\n",
    "-  Cut out the top half of strongly correlated features.<br><br>\n",
    "\n",
    "The following uses the small test dataset, then re-applies it to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix sorted by count:\n",
      "quick and healthy     1\n",
      "basil                 2\n",
      "lemon                 2\n",
      "leftovers             3\n",
      "pineapple             3\n",
      "apple                 5\n",
      "paleo                 5\n",
      "oyster                5\n",
      "good/bad              6\n",
      "party                 6\n",
      "wine                  6\n",
      "turkey                6\n",
      "vegan                 7\n",
      "vegetarian            8\n",
      "parsnip               8\n",
      "winter                8\n",
      "appetizer             9\n",
      "bacon                 9\n",
      "simmer                9\n",
      "thanksgiving         12\n",
      "Name: count, dtype: int64\n",
      "['quick and healthy', 'basil', 'lemon', 'leftovers', 'pineapple']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:16: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "corrmat = new_data.corr()\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "def count_high_corr(row):\n",
    "    count = 0\n",
    "    for index, value in row.iteritems():\n",
    "        if value > 0.01:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "corrmat['count'] = corrmat.apply(lambda row: count_high_corr(row), axis=1)\n",
    "\n",
    "# Apply this feature-counting function to every row in corrmat, store the feature in a new column 'count'\n",
    "# Note: you can't actually produce a new column by iterating through other columns in that row\n",
    "# because you're not directly accessing the row\n",
    "\n",
    "sorted_by_count = corrmat.sort(columns = 'count')\n",
    "print('Correlation Matrix sorted by count:')\n",
    "print(sorted_by_count['count'])\n",
    "\n",
    "best_features = sorted_by_count[:5].index.values.tolist()\n",
    "print(best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that code works, repeat for full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix sorted by count:\n",
      "marinade               5\n",
      "burrito                6\n",
      "idaho                  6\n",
      "fritter                6\n",
      "caviar                 6\n",
      "mezcal                 6\n",
      "dorie greenspan        7\n",
      "camping                7\n",
      "beverly hills          7\n",
      "mississippi            8\n",
      "hummus                 8\n",
      "kitchen olympics       8\n",
      "frankenrecipe          8\n",
      "west virginia          8\n",
      "guam                   8\n",
      "cuba                   9\n",
      "suzanne goin           9\n",
      "england                9\n",
      "custard                9\n",
      "crêpe                  9\n",
      "egypt                  9\n",
      "quiche                 9\n",
      "london                 9\n",
      "costa mesa             9\n",
      "waffle                10\n",
      "nancy silverton       10\n",
      "tested & improved     10\n",
      "hollywood             10\n",
      "#wasteless            10\n",
      "iowa                  10\n",
      "                    ... \n",
      "fall                 155\n",
      "breakfast            155\n",
      "kid-friendly         155\n",
      "tomato               155\n",
      "fruit                157\n",
      "kidney friendly      158\n",
      "winter               159\n",
      "summer               160\n",
      "appetizer            163\n",
      "bake                 165\n",
      "christmas            166\n",
      "vegan                170\n",
      "high fiber           170\n",
      "dessert              177\n",
      "sugar conscious      182\n",
      "good/bad             192\n",
      "no sugar added       195\n",
      "lunch                200\n",
      "healthy              200\n",
      "tree nut free        203\n",
      "wheat/gluten-free    203\n",
      "rating               205\n",
      "bon appétit          206\n",
      "dairy free           208\n",
      "kosher               213\n",
      "vegetarian           214\n",
      "soy free             215\n",
      "peanut free          221\n",
      "pescatarian          222\n",
      "dinner               253\n",
      "Name: count, dtype: int64\n",
      "['marinade', 'burrito', 'idaho', 'fritter', 'caviar', 'mezcal', 'dorie greenspan', 'camping', 'beverly hills', 'mississippi', 'hummus', 'kitchen olympics', 'frankenrecipe', 'west virginia', 'guam', 'cuba', 'suzanne goin', 'england', 'custard', 'crêpe', 'egypt', 'quiche', 'london', 'costa mesa', 'waffle', 'nancy silverton', 'tested & improved', 'hollywood', '#wasteless', 'iowa']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:12: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "corrmat = raw_data.corr()\n",
    "\n",
    "def count_high_corr(row):\n",
    "    count = 0\n",
    "    for index, value in row.iteritems():\n",
    "        if value > 0.01:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "corrmat['count'] = corrmat.apply(lambda row: count_high_corr(row), axis=1)\n",
    "\n",
    "sorted_by_count = corrmat.sort(columns = 'count')\n",
    "print('Correlation Matrix sorted by count:')\n",
    "print(sorted_by_count['count'])\n",
    "\n",
    "best_features = sorted_by_count[:30].index.values.tolist()\n",
    "print(best_features)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of the features with the most individual variance, but it turns out that some of them only have unique variance because they are such obscure features that are used very rarely. These likely would not have much predictive power, so let's try another method of feature reduction.<br>\n",
    "\n",
    "Let's look at the features that have the highest correlation with the outcome, good/bad. We will use the full dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good/bad             1.000000\n",
      "rating               0.655698\n",
      "bon appétit          0.097076\n",
      "roast                0.068198\n",
      "thanksgiving         0.067094\n",
      "peanut free          0.065897\n",
      "soy free             0.065799\n",
      "dinner               0.062186\n",
      "christmas            0.054409\n",
      "grill/barbecue       0.051204\n",
      "tree nut free        0.047943\n",
      "backyard bbq         0.047682\n",
      "fall                 0.046565\n",
      "grill                0.042924\n",
      "stuffing/dressing    0.042454\n",
      "goat cheese          0.041207\n",
      "father's day         0.036564\n",
      "dessert              0.036225\n",
      "meat                 0.035801\n",
      "fourth of july       0.033651\n",
      "low carb             0.033458\n",
      "turkey               0.033409\n",
      "pork tenderloin      0.033370\n",
      "cranberry            0.033333\n",
      "sausage              0.031639\n",
      "cake                 0.031405\n",
      "brisket              0.031385\n",
      "bake                 0.031329\n",
      "red wine             0.031070\n",
      "lamb                 0.030731\n",
      "                       ...   \n",
      "banana              -0.026496\n",
      "non-alcoholic       -0.026749\n",
      "zucchini            -0.026925\n",
      "bread               -0.027742\n",
      "low/no sugar        -0.028034\n",
      "vegetable           -0.028359\n",
      "cabbage             -0.028830\n",
      "chartreuse          -0.028846\n",
      "yogurt              -0.029818\n",
      "quick & easy        -0.031327\n",
      "radish              -0.031962\n",
      "gourmet             -0.032085\n",
      "scotch              -0.032564\n",
      "broccoli            -0.032573\n",
      "liqueur             -0.032672\n",
      "tofu                -0.034426\n",
      "stir-fry            -0.038336\n",
      "vegan               -0.039458\n",
      "rum                 -0.041792\n",
      "harpercollins       -0.042345\n",
      "pasta               -0.043092\n",
      "cocktail            -0.045829\n",
      "low fat             -0.049230\n",
      "bitters             -0.052951\n",
      "spirit              -0.057028\n",
      "cocktail party      -0.063534\n",
      "gin                 -0.071066\n",
      "alcoholic           -0.077158\n",
      "drink               -0.083065\n",
      "house & garden      -0.092801\n",
      "Name: good/bad, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "good_bad_corr = raw_data.corr()['good/bad']\n",
    "good_bad_corr = good_bad_corr.sort_values(ascending = False)\n",
    "print(good_bad_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the best 30 features and use these for the SVC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bon appétit', 'roast', 'thanksgiving', 'peanut free', 'soy free', 'dinner', 'christmas', 'grill/barbecue', 'tree nut free', 'backyard bbq', 'fall', 'grill', 'stuffing/dressing', 'goat cheese', \"father's day\", 'dessert', 'meat', 'fourth of july', 'low carb', 'turkey', 'pork tenderloin', 'cranberry', 'sausage', 'cake', 'brisket', 'bake', 'red wine', 'lamb', 'high fiber', 'pescatarian']\n"
     ]
    }
   ],
   "source": [
    "best_rated_features = good_bad_corr[2:32].index.values.tolist()\n",
    "print(best_rated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.568920805905\n"
     ]
    }
   ],
   "source": [
    "X = raw_data[best_rated_features]\n",
    "Y = raw_data['good/bad']\n",
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(X, Y)\n",
    "\n",
    "print(svm.score(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56569434  0.56918474  0.56394914  0.5713217   0.56223497]\n",
      "0.566476977893\n"
     ]
    }
   ],
   "source": [
    "svm_cv = cross_val_score(svm, X, Y, cv=5)\n",
    "print(svm_cv)\n",
    "print(svm_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is **0.569**. This is not very good, but is at least better than the regressor which was a very poor 0.285. The model is not overfitting, as evidenced by the comparable cross-validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see if we can get a better model by including nutrition information. <br>\n",
    "Drop observations with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       calories   protein       fat    sodium  good/bad  \\\n",
      "rating                 0.007855  0.013971  0.007235  0.008146  0.653233   \n",
      "calories               1.000000  0.742816  0.996538  0.996392  0.012569   \n",
      "protein                0.742816  1.000000  0.712194  0.749287  0.015482   \n",
      "fat                    0.996538  0.712194  1.000000  0.986476  0.012017   \n",
      "sodium                 0.996392  0.749287  0.986476  1.000000  0.012684   \n",
      "#cakeweek             -0.000210 -0.000324 -0.000215 -0.000274 -0.008299   \n",
      "#wasteless            -0.000136 -0.000201 -0.000132 -0.000144  0.007243   \n",
      "22-minute meals       -0.000473 -0.000466 -0.000454 -0.000446  0.019828   \n",
      "3-ingredient recipes  -0.000585 -0.000758 -0.000560 -0.000597 -0.024673   \n",
      "30 days of groceries  -0.000308 -0.000258 -0.000290 -0.000309  0.001083   \n",
      "advance prep required -0.001083 -0.001244 -0.001033 -0.001090 -0.016538   \n",
      "alabama               -0.000132 -0.000195 -0.000128 -0.000140  0.007243   \n",
      "alaska                -0.000178 -0.000188 -0.000173 -0.000164 -0.012308   \n",
      "alcoholic             -0.003346 -0.005073 -0.003316 -0.003582 -0.066905   \n",
      "almond                 0.000574  0.001528  0.000612  0.000667  0.022737   \n",
      "amaretto              -0.000742 -0.001104 -0.000716 -0.000827  0.007155   \n",
      "anchovy               -0.000677 -0.000911 -0.000634 -0.000716  0.000812   \n",
      "anise                 -0.001254 -0.001644 -0.001217 -0.001297 -0.010314   \n",
      "anniversary           -0.001181 -0.001344 -0.001123 -0.001265  0.008476   \n",
      "anthony bourdain      -0.000175 -0.000122 -0.000165 -0.000190 -0.012308   \n",
      "aperitif              -0.000297 -0.000461 -0.000301 -0.000332 -0.019463   \n",
      "appetizer             -0.004423 -0.005876 -0.004207 -0.004251  0.009477   \n",
      "apple                  0.000206  0.001146  0.000220  0.000364  0.004631   \n",
      "apple juice           -0.000294 -0.000411 -0.000287 -0.000327  0.001934   \n",
      "apricot                0.017579  0.009614  0.017754  0.017185  0.018150   \n",
      "arizona               -0.000356 -0.000392 -0.000341 -0.000381  0.003575   \n",
      "artichoke             -0.001410 -0.001590 -0.001334 -0.001419 -0.018950   \n",
      "arugula               -0.001835 -0.002269 -0.001741 -0.001660  0.024335   \n",
      "asian pear            -0.000498 -0.000686 -0.000480 -0.000403 -0.002732   \n",
      "asparagus             -0.001615 -0.001859 -0.001535 -0.001690  0.004240   \n",
      "...                         ...       ...       ...       ...       ...   \n",
      "wasabi                -0.000538 -0.000686 -0.000507 -0.000543  0.006663   \n",
      "washington            -0.000612 -0.000821 -0.000549 -0.000676 -0.002056   \n",
      "washington, d.c.      -0.000367 -0.000450 -0.000350 -0.000391  0.003575   \n",
      "watercress            -0.001360 -0.001683 -0.001269 -0.001426  0.001474   \n",
      "watermelon            -0.000935 -0.001359 -0.000917 -0.001005  0.015682   \n",
      "wedding               -0.001193 -0.001764 -0.001155 -0.001317  0.007995   \n",
      "weelicious            -0.000741 -0.001016 -0.000716 -0.000749 -0.027313   \n",
      "west virginia         -0.000134 -0.000199 -0.000131 -0.000146  0.007243   \n",
      "westwood              -0.000120 -0.000125 -0.000130 -0.000109  0.007243   \n",
      "wheat/gluten-free     -0.000719  0.009050 -0.000471 -0.001711 -0.002359   \n",
      "whiskey               -0.000869 -0.001233 -0.000856 -0.000945 -0.003712   \n",
      "white wine            -0.002607 -0.002303 -0.002505 -0.002494  0.012926   \n",
      "whole wheat           -0.000649 -0.000927 -0.000632 -0.000676 -0.013350   \n",
      "wild rice             -0.000435 -0.000468 -0.000425 -0.000451 -0.016344   \n",
      "windsor               -0.000078  0.000596 -0.000106  0.000255  0.007243   \n",
      "wine                  -0.001584 -0.001958 -0.001526 -0.001665  0.008026   \n",
      "winter                 0.011178  0.021620  0.011342  0.010215  0.013166   \n",
      "wisconsin             -0.000263 -0.000308 -0.000256 -0.000265 -0.001460   \n",
      "wok                   -0.001222 -0.001437 -0.001172 -0.001184 -0.015388   \n",
      "yellow squash         -0.000599 -0.000860 -0.000578 -0.000622 -0.010401   \n",
      "yogurt                -0.002496 -0.003120 -0.002388 -0.002618 -0.018641   \n",
      "yonkers               -0.000135 -0.000197 -0.000132 -0.000138  0.007243   \n",
      "yuca                  -0.000292 -0.000354 -0.000289 -0.000302  0.009067   \n",
      "zucchini              -0.001979 -0.002566 -0.001894 -0.002032 -0.024408   \n",
      "cookbooks             -0.000181 -0.000232 -0.000175 -0.000173 -0.001032   \n",
      "leftovers             -0.000285 -0.000290 -0.000278 -0.000287 -0.019463   \n",
      "snack                 -0.000619 -0.000883 -0.000594 -0.000638 -0.015533   \n",
      "snack week            -0.000486 -0.000702 -0.000464 -0.000508 -0.004844   \n",
      "turkey                -0.002267 -0.000748 -0.002215 -0.001867  0.039578   \n",
      "good/bad               0.012569  0.015482  0.012017  0.012684  1.000000   \n",
      "\n",
      "                         rating  \n",
      "rating                 1.000000  \n",
      "calories               0.007855  \n",
      "protein                0.013971  \n",
      "fat                    0.007235  \n",
      "sodium                 0.008146  \n",
      "#cakeweek              0.002987  \n",
      "#wasteless             0.007653  \n",
      "22-minute meals        0.017687  \n",
      "3-ingredient recipes  -0.051262  \n",
      "30 days of groceries   0.007118  \n",
      "advance prep required -0.025939  \n",
      "alabama                0.007653  \n",
      "alaska                -0.000096  \n",
      "alcoholic             -0.209148  \n",
      "almond                 0.005499  \n",
      "amaretto               0.013279  \n",
      "anchovy               -0.018940  \n",
      "anise                 -0.002684  \n",
      "anniversary            0.010505  \n",
      "anthony bourdain      -0.021934  \n",
      "aperitif              -0.022597  \n",
      "appetizer              0.023534  \n",
      "apple                  0.003790  \n",
      "apple juice           -0.003604  \n",
      "apricot                0.009421  \n",
      "arizona                0.007999  \n",
      "artichoke             -0.004597  \n",
      "arugula                0.020244  \n",
      "asian pear             0.001811  \n",
      "asparagus              0.012152  \n",
      "...                         ...  \n",
      "wasabi                 0.009088  \n",
      "washington             0.008161  \n",
      "washington, d.c.       0.006634  \n",
      "watercress             0.001504  \n",
      "watermelon             0.012365  \n",
      "wedding               -0.001045  \n",
      "weelicious            -0.063155  \n",
      "west virginia          0.003793  \n",
      "westwood               0.003793  \n",
      "wheat/gluten-free      0.014778  \n",
      "whiskey               -0.036759  \n",
      "white wine             0.027213  \n",
      "whole wheat           -0.003486  \n",
      "wild rice             -0.000234  \n",
      "windsor                0.003793  \n",
      "wine                  -0.004633  \n",
      "winter                 0.058439  \n",
      "wisconsin              0.001795  \n",
      "wok                    0.000602  \n",
      "yellow squash         -0.001166  \n",
      "yogurt                -0.013485  \n",
      "yonkers                0.007653  \n",
      "yuca                   0.008482  \n",
      "zucchini               0.001311  \n",
      "cookbooks              0.002634  \n",
      "leftovers             -0.051949  \n",
      "snack                 -0.050885  \n",
      "snack week            -0.015239  \n",
      "turkey                 0.022338  \n",
      "good/bad               0.653233  \n",
      "\n",
      "[680 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "nutrition = raw_data.dropna()\n",
    "nutrition_corr = nutrition.corr()[['calories', 'protein', 'fat', 'sodium', 'good/bad', 'rating']]\n",
    "print(nutrition_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the nutritional features to the \"best features\" list (features were ranked by their correlation to the outcome.)<br>\n",
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"X = nutrition[best_rated_features + ['calories', 'protein', 'fat', 'sodium']]\\nY = nutrition['good/bad']\\nsvm = SVC(kernel = 'linear')\\nsvm.fit(X, Y)\\n\\nprint(svm.score(X,Y))\\nsvm_cv = cross_val_score(svm, X, Y, cv=5)\\nprint(svm_cv.mean())\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X = nutrition[best_rated_features + ['calories', 'protein', 'fat', 'sodium']]\n",
    "Y = nutrition['good/bad']\n",
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(X, Y)\n",
    "\n",
    "print(svm.score(X,Y))\n",
    "svm_cv = cross_val_score(svm, X, Y, cv=5)\n",
    "print(svm_cv.mean())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is too computationally expensive to train with SVC. LinearSVC tends to be faster to converge the larger the number of samples is, so we will try LinearSVC. Alternatively, if this still doesn't converge, we could try training with less data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: 0.0001\n",
      "0.569402420575\n",
      "\n",
      "C: 0.001\n",
      "0.571482602118\n",
      "\n",
      "C: 0.1\n",
      "0.560199193142\n",
      "\n",
      "C: 1\n",
      "0.455937972769\n",
      "\n",
      "C: 10\n",
      "0.547844175492\n"
     ]
    }
   ],
   "source": [
    "X = nutrition[best_rated_features + ['calories', 'protein', 'fat', 'sodium']]\n",
    "Y = nutrition['good/bad']\n",
    "c_values = [0.0001, 0.001, 0.1, 1, 10]\n",
    "for c in c_values:\n",
    "    svm = LinearSVC(C = c, random_state=1)\n",
    "    svm.fit(X, Y)\n",
    "    print(f'\\nC: {c}')\n",
    "    print(svm.score(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When C = 0.001, the model performs the best. However, an accuracy score of **0.57** is not particularly good, and varying the C parameter does not have a huge impact on the score. Adding in the nutrition features did not significantly improve the score from before, which was also about 0.57. <br>\n",
    "\n",
    "Let's try one more method of feature selection, SelectKBest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: 0.0001\n",
      "0.568621583882\n",
      "\n",
      "C: 0.001\n",
      "0.578944743666\n",
      "\n",
      "C: 0.1\n",
      "0.586824256932\n",
      "\n",
      "C: 1\n",
      "0.586874127269\n",
      "\n",
      "C: 10\n",
      "0.586874127269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "X = raw_data.drop(['rating', 'title', 'calories', 'protein', 'fat', 'sodium', 'good/bad'], 1)\n",
    "Y = raw_data['good/bad']\n",
    "\n",
    "X_k30 = SelectKBest(k=30).fit_transform(X,Y)\n",
    "\n",
    "for c in c_values:\n",
    "    svm = LinearSVC(C = c, random_state=1)\n",
    "    svm.fit(X_k30, Y)\n",
    "    print(f'\\nC: {c}')\n",
    "    print(svm.score(X_k30,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By using LinearSVC with the 30 best features as determined by SelectKBest, we see a very minor improvement in the score from 0.571 to **0.587.** SelectKBest is a powerful tool that uses the F statistic to eliminate less impactful features. In this case, using SelectKBest over manually picking features that correlated highly with the outcome resulted in a very small increase in performance. <br>\n",
    "\n",
    "In the future, I would try including more features with the SelectKBest method of feature reduction, and running the model on a machine that can handle the full SVC object and not just the LinearSVC modification. Even still, it is possible that the buzzwords in a recipe title may not have predictive power for the recipe rating. Two recipes could both use \"tomato\", but one could be horrible and one could be great. It also depends on the proficiency of the reader in following recipes, which is another confounding factor that is not accounted for in these features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
